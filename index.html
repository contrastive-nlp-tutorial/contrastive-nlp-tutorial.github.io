<!DOCTYPE html>
<html lang="en-US">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <meta charset="UTF-8">
      <!-- Begin Jekyll SEO tag v2.6.1 -->
      <title>Contrastive Data and Learning for Natural Language Processing</title>
      <meta name="generator" content="Jekyll v3.9.0">
      <meta property="og:title" content="Welcome">
      <meta property="og:locale" content="en_US">
      <meta name="description" content="Contrastive Data and Learning for Natural Language Processing">
      <meta property="og:description" content="Contrastive Data and Learning for Natural Language Processing">
      <link rel="canonical" href="https://contrastive-nlp-tutorial.github.io/">
      <meta property="og:url" content="https://contrastive-nlp-tutorial.github.io/">
      <meta property="og:site_name" content="Contrastive Data and Learning for Natural Language Processing">
      <script type="application/ld+json">
         {"description":"Contrastive Data and Learning for Natural Language Processing","name":"Contrastive Data and Learning for Natural Language Processing","@type":"WebSite","url":"https://contrastive-nlp-tutorial.github.io/","headline":"Welcome","@context":"https://schema.org"}
      </script>
      <!-- End Jekyll SEO tag -->
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="theme-color" content="#157878">
      <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
      <link rel="stylesheet" href="/assets/css/style.css?v=c64178984bc3b4827ae20ab3ebe9e05d036cc516">
   </head>
   <body>
      <header class="page-header" role="banner">
         <h1>Contrastive Data and Learning for Natural Language Processing</h1>
         <h2>Tutorial at NAACL 2022</h2>
      </header>
      <main id="content" class="main-content" role="main">
         <h2 id="abstract">Abstract</h2>
            <p>How information is created, shared and consumed has changed rapidly in recent decades, in part thanks to new social platforms and technologies on the web. With ever-larger amounts of unstructured and limited labels, organizing and reconciling information from different sources and modalities is a central challenge in machine learning.
            <br><br>
            This cutting-edge tutorial aims to introduce the multimodal entailment task, which can be useful for detecting semantic alignments when a single modality alone does not suffice for a whole content understanding. Starting with a brief overview of natural language processing, computer vision, structured data and neural graph learning, we lay the foundations for the multimodal sections to follow. We then discuss recent multimodal learning literature covering visual, audio and language streams, and explore case studies focusing on tasks which require fine-grained understanding of visual and linguistic semantics question answering, veracity and hatred classification. Finally, we introduce a new dataset for recognizing multimodal entailment, exploring it in a hands-on collaborative section. 
            <br><br>
            Overall, this tutorial gives an overview of multimodal learning, introduces a multimodal entailment dataset, and encourages future research in the topic.
            </p>
         <h2 id="outline">Outline</h2>
         <table>
            <tbody>
               <tr>
                  <td>Section</td>
                  <td>Subsection</td>
                  <td style="text-align:right;">min</td>
               </tr>
               <tr>
                  <td rowspan="2">Introduction
                     <br>
                  </td>
                  <td>The landscape of online content</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td>A case for multimodal entailment inferences</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td rowspan="3">Natural
                     <br>
                     Language
                     <br>
                     Processing
                  </td>
                  <td>From word embeddings to contextualized representations</td>
                  <td style="text-align:right;">15</td>
               </tr>
               <tr>
                  <td>Fine-tuning pretrained models on downstream tasks</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td>The textual entailment problem</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td rowspan="2">Structured Data
                     <br>
                  </td>
                  <td>Semi-structured and tabular text</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td>Knowledge graphs</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td>Neural Graph Learning</td>
                  <td>Leveraging structured signals with Neural Structured Learning</td>
                  <td style="text-align:right;">10</td>
               </tr>
               <tr>
                  <td>Computer Vision</td>
                  <td>Foundations of Computer Vision</td>
                  <td style="text-align:right;">20</td>
               </tr>
               <tr>
                  <td>Break</td>
                  <td>-</td>
                  <td style="text-align:right;">10</td>
               </tr>
               <tr>
                  <td rowspan="3">Multimodal Learning
                     <br><br>
                  </td>
                  <td>Attention Bottlenecks for Multimodal Fusion: state-of-the-art audio-visual classifications</td>
                  <td style="text-align:right;">15</td>
               </tr>
               <tr>
                  <td>Self-Supervised Multimodal Versatile Networks:  visual, audio and language streams</td>
                  <td style="text-align:right;">25</td>
               </tr>
               <tr>
                  <td>Case studies: cross-modal fine-grained reasoning</td>
                  <td style="text-align:right;">15</td>
               </tr>
               <tr>
                  <td>Break</td>
                  <td>-</td>
                  <td style="text-align:right;">10</td>
               </tr>
               <tr>
                  <td rowspan="2">Multimodal entailment
                     <br>
                  </td>
                  <td>Multimodal models for entailment inferences</td>
                  <td style="text-align:right;">20</td>
               </tr>
               <tr>
                  <td>Multimodal entailment dataset</td>
                  <td style="text-align:right;">10</td>
               </tr>
               <tr>
                  <td rowspan="2">Final considerations
                     <br>
                  </td>
                  <td>Closing notes</td>
                  <td style="text-align:right;">5</td>
               </tr>
               <tr>
                  <td>Q&amp;A</td>
                  <td style="text-align:right;">30</td>
               </tr>
               <tr>
                  <td>Total</td>
                  <td>â€“</td>
                  <td style="text-align:right;">210</td>
               </tr>
            </tbody>
         </table>
         <h2 id="slides">Slides</h2>
         <iframe
            src="https://docs.google.com/presentation/d/e/2PACX-1vRVO9RA5Pyd0LDVoVM8pH0BExX871rgnuAEQqQQ7LXtSZzHaosCxeaVhZ3u__h04BHcLGIBvv1zv7uF/pub?start=false&loop=false&delayms=3000"
            frameborder="0"
            max-width="100%"
            width="800"
            height="600"
            ></iframe>

         <h2 id="reading-list">Reading list</h2>
         
         <h2 id="tutors">Presenters</h2>
         <div style="display: flex">
            <div style="width:20%;" align="center">
               <img alt="Rui Zhang" src="./images/ruizhang.jpeg" style="max-width:100%;">
               </a><br>
               Rui Zhang,<br>Penn State University
            </div>
            <div style="width:2%">
            </div>
            <div style="width:20%;" align="center">
               <img alt="Rui Zhang" src="./images/ruizhang.jpeg" style="max-width:100%;">
               </a><br>
               Rui Zhang,<br>Penn State University
            </div>
            <div style="width:2%">
            </div>
            <div style="width:20%;" align="center">
               <img alt="Rui Zhang" src="./images/ruizhang.jpeg" style="max-width:100%;">
               </a><br>
               Rui Zhang,<br>Penn State University
            </div>
            <div style="width:20%;" align="center">
               <img alt="Rui Zhang" src="./images/ruizhang.jpeg" style="max-width:100%;">
               </a><br>
               Rui Zhang,<br>Penn State University
            </div>
         </div>
      </main>
   </body>
</html>